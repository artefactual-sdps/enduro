package client

import (
	"context"
	"fmt"
	"time"

	"github.com/google/uuid"

	"github.com/artefactual-sdps/enduro/internal/datatypes"
	"github.com/artefactual-sdps/enduro/internal/entfilter"
	"github.com/artefactual-sdps/enduro/internal/persistence"
	"github.com/artefactual-sdps/enduro/internal/persistence/ent/db"
	"github.com/artefactual-sdps/enduro/internal/persistence/ent/db/batch"
	"github.com/artefactual-sdps/enduro/internal/persistence/ent/db/user"
)

// CreateBatch creates and persists a new Batch using the values from b
// then returns the updated Batch.
//
// The input Batch "ID" and "CreatedAt" values are ignored; the stored Batch
// "ID" is generated by the persistence implementation and "CreatedAt" is always
// set to the current time.
func (c *client) CreateBatch(ctx context.Context, b *datatypes.Batch) error {
	// Validate required fields.
	if b.UUID == uuid.Nil {
		return newRequiredFieldError("UUID")
	}
	if b.Identifier == "" {
		return newRequiredFieldError("Identifier")
	}
	if b.SIPSCount <= 0 {
		return newRequiredFieldError("SIPSCount")
	}

	tx, err := c.ent.BeginTx(ctx, nil)
	if err != nil {
		return newDBErrorWithDetails(err, "create Batch")
	}

	q := tx.Batch.Create().
		SetUUID(b.UUID).
		SetIdentifier(b.Identifier).
		SetStatus(b.Status).
		SetSipsCount(b.SIPSCount).
		SetCreatedAt(time.Now())

	// Add optional fields.
	if b.StartedAt.Valid {
		q.SetStartedAt(b.StartedAt.Time)
	}
	if b.CompletedAt.Valid {
		q.SetCompletedAt(b.CompletedAt.Time)
	}

	// If Uploader is set, find or create the user and link it to the Batch.
	if b.Uploader != nil {
		uID, err := findOrCreateOIDCUser(ctx, tx.Client(), b.Uploader)
		if err != nil {
			return rollback(tx, err)
		}

		q.SetUploaderID(uID)
	}

	// Save the Batch.
	dbb, err := q.Save(ctx)
	if err != nil {
		return rollback(tx, newDBErrorWithDetails(err, "create Batch"))
	}
	if err = tx.Commit(); err != nil {
		return rollback(tx, newDBError(err))
	}

	// Update Batch with DB data, to get generated values (e.g. ID). Manually set
	// the uploader data because the dbb result doesn't include the user edge.
	uploader := b.Uploader
	*b = *convertBatch(dbb)
	b.Uploader = uploader

	return nil
}

// UpdateBatch updates the persisted Batch identified by id using the
// updater function, then returns the updated Batch.
//
// The Batch "ID", "UUID", "CreatedAt", and "UploaderID" values can not be updated
// with this method.
func (c *client) UpdateBatch(
	ctx context.Context,
	id uuid.UUID,
	updater persistence.BatchUpdater,
) (*datatypes.Batch, error) {
	tx, err := c.ent.BeginTx(ctx, nil)
	if err != nil {
		return nil, newDBError(err)
	}

	// Get the current Batch data from the database.
	dbb, err := tx.Batch.Query().
		Where(batch.UUID(id)).
		WithUploader().
		Only(ctx)
	if err != nil {
		return nil, rollback(tx, newDBError(err))
	}

	// Keep database ID in case it's changed by the updater.
	dbID := dbb.ID

	// Get the uploader data so we can set it on the returned Batch later.
	var uploader *datatypes.User
	if dbb.Edges.Uploader != nil {
		uploader = convertUser(dbb.Edges.Uploader)
	}

	// Get an updated datatypes.Batch from the updater function.
	up, err := updater(convertBatch(dbb))
	if err != nil {
		return nil, rollback(tx, newUpdaterError(err))
	}

	// Save the updated Batch data to the database.
	q := tx.Batch.UpdateOneID(dbID).SetIdentifier(up.Identifier)

	// Validate columns.
	if up.Status.IsValid() {
		q.SetStatus(up.Status)
	}
	if up.SIPSCount > 0 {
		q.SetSipsCount(up.SIPSCount)
	}

	// Set optional column values.
	if up.StartedAt.Valid {
		q.SetStartedAt(up.StartedAt.Time)
	}
	if up.CompletedAt.Valid {
		q.SetCompletedAt(up.CompletedAt.Time)
	}

	// Save changes.
	dbb, err = q.Save(ctx)
	if err != nil {
		return nil, rollback(tx, newDBError(err))
	}
	if err = tx.Commit(); err != nil {
		return nil, rollback(tx, newDBError(err))
	}

	b := convertBatch(dbb)

	// Set the uploader data on the returned Batch.
	b.Uploader = uploader

	return b, nil
}

// DeleteBatch deletes the persisted Batch identified by id.
func (c *client) DeleteBatch(ctx context.Context, id uuid.UUID) error {
	n, err := c.ent.Batch.Delete().Where(batch.UUID(id)).Exec(ctx)
	if err != nil {
		return newDBErrorWithDetails(err, "delete Batch")
	}
	if n == 0 {
		return fmt.Errorf("%w: %s", persistence.ErrNotFound, "db: batch not found: delete Batch")
	}

	return nil
}

// ReadBatch returns the Batch identified by id.
func (c *client) ReadBatch(ctx context.Context, id uuid.UUID) (*datatypes.Batch, error) {
	b, err := c.ent.Batch.Query().
		Where(batch.UUID(id)).
		WithUploader().
		Only(ctx)
	if err != nil {
		return nil, newDBError(err)
	}

	return convertBatch(b), nil
}

// ListBatches returns a slice of Batches filtered according to f.
func (c *client) ListBatches(ctx context.Context, f *persistence.BatchFilter) (
	[]*datatypes.Batch, *persistence.Page, error,
) {
	if f == nil {
		f = &persistence.BatchFilter{}
	}

	q := c.ent.Batch.Query().WithUploader()

	if f.UploaderID != nil {
		q.Where(batch.HasUploaderWith(user.UUID(*f.UploaderID)))
	}

	page, whole := filterBatches(q, f)

	r, err := page.All(ctx)
	if err != nil {
		return nil, nil, newDBError(err)
	}

	res := make([]*datatypes.Batch, len(r))
	for i, dbb := range r {
		res[i] = convertBatch(dbb)
	}

	total, err := whole.Count(ctx)
	if err != nil {
		return nil, nil, newDBError(err)
	}

	pp := &persistence.Page{
		Limit:  f.Limit,
		Offset: f.Offset,
		Total:  total,
	}

	return res, pp, err
}

// filterBatches applies the Batch filter f to the query q.
func filterBatches(q *db.BatchQuery, f *persistence.BatchFilter) (page, whole *db.BatchQuery) {
	qf := entfilter.NewFilter(q, entfilter.SortableFields{
		batch.FieldID: {Name: "ID", Default: true},
	})
	qf.Contains(batch.FieldIdentifier, f.Identifier)
	qf.Equals(batch.FieldStatus, f.Status)
	qf.AddDateRange(batch.FieldCreatedAt, f.CreatedAt)
	qf.OrderBy(f.Sort)
	qf.Page(f.Limit, f.Offset)

	// Update the BatchFilter values with the actual values set on the query.
	// E.g. calling `qf.Page(0,0)` will set the query limit equal to the default
	// page size.
	f.Limit = qf.Limit
	f.Offset = qf.Offset

	return qf.Apply()
}
