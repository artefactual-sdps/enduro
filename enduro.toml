# This is the configuration file valid for the development environment.

debug = true
debugListen = "127.0.0.1:9001"
verbosity = 2

[temporal]
namespace = "default"
address = "temporal.enduro-sdps:7233"
taskQueue = "global"

[api]
listen = "0.0.0.0:9000"
debug = false
corsOrigin = "http://localhost"

[api.auth]
# Enable API authentication. OIDC is the only protocol supported at the
# moment. When enabled the API verifies the access token submitted with 
# each request. The API client is responsible for obtaining an access
# token from the provider.
enabled = true

[api.auth.oidc]
# OIDC provider URL. Required when auth. is enabled.
providerURL = "http://keycloak:7470/realms/artefactual"
# OIDC client ID. The client ID must be included in the `aud` claim of
# the access token. Required when auth. is enabled. 
clientID = "enduro"

[api.auth.oidc.abac]
# Enable Attribute Based Access Control (ABAC). If enabled, the API will
# check a configurable multivalue claim against required attributes based
# on each endpoint configuration.
enabled = true
# Claim path of the Enduro attributes within the access token. If the claim
# path is nested then include all fields separated by `claimPathSeparator`
# (see below). E.g. "attributes.enduro" with `claimPathSeparator = "."`. 
# Required when ABAC is enabled.
claimPath = "enduro"
# Separator used to split the claim path fields. The default value of "" will
# try to match the claim path as-is to a top-level field from the access token.
claimPathSeparator = ""
# Add a prefix to filter the values of the configured claim. If the claim
# contains values unrelated to Enduro's ABAC, the values relevant to Enduro
# should be prefixed so they are the only values used for access control.
# For example, a claim with values ["enduro:*", "unrelated"] will be filtered
# to a value of ["*"] when `claimValuePrefix = "enduro:"`. The default "" will
# not filter any value.
claimValuePrefix = ""

[api.auth.ticket.redis]
address = "redis://redis.enduro-sdps:6379"
prefix = "enduro"

[database]
driver = "mysql"
dsn = "enduro:enduro123@tcp(mysql.enduro-sdps:3306)/enduro"
migrate = true

[event]
redisAddress = "redis://redis.enduro-sdps:6379"
redisChannel = "enduro-events"

[extractActivity]
dirMode = "0o700"
fileMode = "0o600"

[watcher.embedded]
name = "dev-minio"
redisAddress = "redis://redis.enduro-sdps:6379"
redisList = "minio-events"
endpoint = "http://minio.enduro-sdps:9000"
pathStyle = true
key = "minio"
secret = "minio123"
region = "us-west-1"
bucket = "sips"
stripTopLevelDir = true

[storage]
enduroAddress = "enduro.enduro-sdps:9000"

# defaultPermanentLocationId is the UUID of the storage location used for
# permanent AIP storage in the "auto-approve" processing workflow. The value of
# "f2cc963f-c14d-4eaa-b950-bd207189a1f1" represents the first permanent location
# defined in the mysql-create-locations-job.yaml Kubernetes manifest.
defaultPermanentLocationId = "f2cc963f-c14d-4eaa-b950-bd207189a1f1"

[storage.database]
driver = "mysql"
dsn = "enduro:enduro123@tcp(mysql.enduro-sdps:3306)/enduro_storage"
migrate = true

[storage.internal]
endpoint = "http://minio.enduro-sdps:9000"
pathStyle = true
key = "minio"
secret = "minio123"
region = "us-west-1"
bucket = "aips"

# Change the taskqueue setting to your prefered preservation system, by default it is a3m.
[preservation]
taskqueue = "a3m"

[a3m]
address = "127.0.0.1:7000"
shareDir = "/home/a3m/.local/share/a3m/share"

# capacity limits the number of transfers a worker can process at one time
# (default: 1)
capacity = 1

[a3m.processing]
AssignUuidsToDirectories                     = true
ExamineContents                              = true
GenerateTransferStructureReport              = true
DocumentEmptyDirectories                     = true
ExtractPackages                              = true
DeletePackagesAfterExtraction                = true
IdentifyTransfer                             = true
IdentifySubmissionAndMetadata                = true
IdentifyBeforeNormalization                  = true
Normalize                                    = true
TranscribeFiles                              = true
PerformPolicyChecksOnOriginals               = true
PerformPolicyChecksOnPreservationDerivatives = true
AipCompressionLevel                          = 1
AipCompressionAlgorithm                      = 6

[am]
address = ""
user = "" # Secret: set with env var ENDURO_AM_USER.
apiKey = "" # Secret: set with env var ENDURO_AM_APIKEY.
processingConfig = "automated"

# capacity limits the number of transfers a worker can process at one time
# (default: 1)
capacity = 1

# pollInterval is the time to wait between AM polling requests in a string
# format compatible with https://pkg.go.dev/time#ParseDuration (Default: 10s).
pollInterval = "10s"

# transferDeadline is the maximum time to wait for a transfer to complete in a
# format compatible with https://pkg.go.dev/time#ParseDuration. Set to "0" for
# no time limit.
transferDeadline = "1h"

[am.sftp]
host = "" # The Archivematica Storage Service hostname.
port = ""
user = ""
knownHostsFile = ""
remoteDir = "/transfer_source"

[am.sftp.privateKey]
path = ""
passphrase = "" # Secret: set (if required) with env var ENDURO_AM_SFTP_PRIVATEKEY_PASSPHRASE.

[upload]
endpoint = "http://minio.enduro-sdps:9000"
pathStyle = true
key = "minio"
secret = "minio123"
region = "us-west-1"
bucket = "sips"

[telemetry.traces]
enabled = false
address = ""
samplingRatio = 1.0

# Optional preprocessing child workflow configuration.
[preprocessing]
# enabled triggers the execution of the child workflow, when set to false all other
# options are ignored.
enabled = false
# extract determines if the package extraction happens on the child workflow.
extract = false
# sharedPath is the full path to the directory used to share the package between workflows,
# required when enabled is set to true.
sharedPath = "/home/enduro/preprocessing"

# Temporal configuration to trigger the preprocessing child workflow, all fields are
# required when enabled is set to true.
[preprocessing.temporal]
namespace = "default"
taskQueue = "preprocessing"
workflowName = "preprocessing"
